{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cde06b-b47b-464e-a1ef-c2e6e7bc4b72",
   "metadata": {},
   "source": [
    "# Key Takeaways\n",
    "\n",
    "We will typically download data from the internet using a handful of Python packages.\n",
    "This approach avoids manually downloading and importing data files from multiple websites.\n",
    "This notebook provides a tutorial on how to use the yfinance, pandas-datareader, and requests-cache packages to download data.\n",
    "For completeness, this tutorial also covers saving to and reading from .csv and .pkl files, which are easier to share.\n",
    "\n",
    "***The key takeaways from this notebook are:***\n",
    "\n",
    "1. Downloading data with the yfinance and pandas-datareader packages\n",
    "1. Saving and sharing data with .csv and .pkl files (comma-separated value and pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf9e81-6997-47e4-9eaa-fd35db4e0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d431f66-2203-44d3-bcdc-369ec1acc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 150\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646c60d-6b7e-417d-a5c4-5be32e7b2e9c",
   "metadata": {},
   "source": [
    "# The yfinance Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d23e6-ec23-4ed1-ab0f-1bf7f4395a87",
   "metadata": {},
   "source": [
    "The [yfinance package](https://github.com/ranaroussi/yfinance) provides \"a reliable, threaded, and Pythonic way to download historical market data from Yahoo! finance.\"\n",
    "Other packages that provide similar functionality, but I think yfinance is the best when I last searched for alternatives in September 2021.\n",
    "To avoid repeated calls to Yahoo! Finance's advanced programming interface (API), we will use the requests-cache package.\n",
    "We can install these packages with the `%pip` magic by running the following cell once per Anaconda installation or DataCamp Workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1cd5c-2004-4018-80d6-4c051c23620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install yfinance requests-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833f5b6-fc8d-4b2b-9eb3-f62a8d649306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import requests_cache\n",
    "session = requests_cache.CachedSession(expire_after='1D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f48786-1da2-472f-8759-bddd5ca30507",
   "metadata": {},
   "source": [
    "We can download data for the FAANG stocks (Facebook, Amazon, Apple, Netflix, and Google).\n",
    "We can pass tickers as either a space-delimited string or a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3feef9-b44d-4144-a7a5-b5abaace1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = yf.download(tickers='FB AMZN AAPL NFLX GOOG', session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e3331-d03d-43eb-833f-52197ecee187",
   "metadata": {},
   "source": [
    "We can plot the value of 100 dollars invested in each of the stocks at the close on the last day of 2020.\n",
    "We can chain the following steps:\n",
    "\n",
    "1. Calculate returns\n",
    "1. Subset to 2021 and beyond\n",
    "1. Compound returns\n",
    "1. Multiply by 100\n",
    "\n",
    "Then plot.\n",
    "Note that I subtract one business month from the index to find the date of the previous close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c86aa-3927-491a-9b73-e1bdfdc0539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = faang['Adj Close'].pct_change().loc['2021':].add(1).cumprod().mul(100)\n",
    "_.plot()\n",
    "buy_date = (_.index[0] - pd.offsets.BusinessMonthEnd()).strftime('%B %d, %Y')\n",
    "plt.title('Value of $100 Invested in FAANG Stocks at Close on ' + buy_date)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0ac14-c5bd-4db2-ba18-cad5c0621669",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4e04b-1837-4df1-8506-28acb89baa16",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Can we make the plot above without compounding returns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b6422-d49a-44c1-8383-7fee25ba1e69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c237cfa-3780-462f-b585-51a87d38c2ad",
   "metadata": {},
   "source": [
    "The easiest, and most universal way to save data is to a .csv file with the `.to_csv()` method.\n",
    "Note that I save notebooks and data to folders named Notebooks and Data that are at the same level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1b9d2-ef55-4b2c-b2f5-b3e9baa7ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.to_csv('../../Data/FAANG.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596e14c8-e7a2-40a6-b8ed-f29829562532",
   "metadata": {},
   "source": [
    "With one column index, the `.to_csv()` is great.\n",
    "However, the column multi-index of this data frame make reading this .csv file tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636327a-624c-4222-b27b-75d64f1f4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../../Data/FAANG.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009cc50-9422-4fbc-a719-37837d3c5a88",
   "metadata": {},
   "source": [
    "If we we will typically use data with Python, a .pkl file is a better than a .csv file.\n",
    "A .pkl file stores/reloads the pandas object as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83593cb0-ad51-4a50-93f6-9315c11da6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.to_pickle('../../Data/FAANG.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b08305-79cc-43a2-a1e1-589f556279eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('../../Data/FAANG.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e2374-7dc3-48df-a445-a247b8b0a637",
   "metadata": {},
   "source": [
    "If we want to save our data as a .csv file, we should convert our data to a long format.\n",
    "In a long format, each variable (e.g., adjusted close) appears in one and only one column, and each row represents one stock on one date.\n",
    "We can use the `.stack()` method to convert from wide data to long data.\n",
    "We will cover `.stack()` and `.unstack()` methods in greater detail later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4c2a0-4d26-416f-b53b-cec7a306d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.columns.names = ['Variable', 'Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47676228-b822-42fe-bd9a-251d03eaf572",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.stack().to_csv('../../Data/FAANG-long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e18a8-2683-4d19-8c9a-6d1c4f92c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_long = pd.read_csv('../../Data/FAANG-long.csv', index_col=['Date', 'Ticker'], parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0dd6b2-b6d7-4c89-81e2-e79df82380f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8796ece-67ba-47e5-b511-13d131b87fea",
   "metadata": {},
   "source": [
    "***Practice:***\n",
    "Manipulate `faang_long` to match the original `faang` (i.e., wide format)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94179456-df78-4db0-9fa7-d11935c562f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a8e19-e0c8-4640-8748-3b13bb6d0eb6",
   "metadata": {},
   "source": [
    "# The pandas-datareader package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332ecfe-f4cd-4231-8ea1-69d9200706e5",
   "metadata": {},
   "source": [
    "The [pandas-datareader](https://pandas-datareader.readthedocs.io/en/latest/index.html) package provides easy access to a variety of data sources, such as \n",
    "[Ken French's Data Library](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html) \n",
    "and \n",
    "[Federal Reserve Economic Data (FRED)](https://fred.stlouisfed.org/).\n",
    "The pandas-datareader package also provides access to Yahoo! Finance data, but I think the yfinance package has better documentation.\n",
    "We can install pandas-datareader with the `%pip` magic by running the following cell once per Anaconda installation or DataCamp Workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cb6de-9662-4699-8ce6-0e34d3a2758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84c7ab-b1aa-473a-b41f-da080f36787a",
   "metadata": {},
   "source": [
    "We will use `pdr` as the abbreviated prefix for pandas-datareader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acffb20-3d5f-4aeb-86ec-75e2f84b3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a117e7-a7ac-4e04-b760-ac3c99767d60",
   "metadata": {},
   "source": [
    "He is an example with the daily benchmark factor from Ken French's Data Library.\n",
    "The `get_available_datasets()` function provides the exact names for all of Ken French's data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d5792-b0cb-4279-9bf2-6e066cdd93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdr.famafrench.get_available_datasets()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e92f7-deff-424a-8b77-6181df3a752c",
   "metadata": {},
   "source": [
    "Note that pandas-datareader returns a dictionary of data frames and we specify a `start` date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9ec1f-4f4f-42b5-a237-35c81de9e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = pdr.get_data_famafrench('F-F_Research_Data_Factors_daily', start='1900', session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd5c68-d1da-44bb-9a05-1ea79f79533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff[0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e5397-a77a-442d-a406-90c19eb1fb10",
   "metadata": {},
   "source": [
    "By default, pandas-datareader downloads five years of data, but most Fama-French data are available back through the mid 1920s.\n",
    "We can easily plot the cumulative returns to the Fama-French factors over the past five years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bd081-bc6f-4d99-9308-06cc4a52ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff[0].div(100).add(1).cumprod().plot()\n",
    "buy_date = (ff[0].index[0] - pd.offsets.BusinessDay()).strftime('%B %d, %Y')\n",
    "plt.title('Value of $1 Invested in FF Factors at Close on ' + buy_date)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value ($)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author": "Richard Herron",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "title": "Downloading and Saving Data"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
